{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a527b72ba564c079765ff50fb2eb757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ce05a51d8084243ae2ad7ce1116df69",
              "IPY_MODEL_49085b35aa054e048af6f2b036c459b5",
              "IPY_MODEL_49aed82b08514535bcc8a9654e1956c5"
            ],
            "layout": "IPY_MODEL_a5ea3e49c7a444ceb360aa154ea478e8"
          }
        },
        "2ce05a51d8084243ae2ad7ce1116df69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5205e42106fb455ca0adf77086ba101a",
            "placeholder": "​",
            "style": "IPY_MODEL_be00f6a3713c45f2b43a16896d84dfa0",
            "value": "model.safetensors: 100%"
          }
        },
        "49085b35aa054e048af6f2b036c459b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cca5bfaf63304c41a1e74baa94de8cf8",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf50d571ce26482089837db7fd881f35",
            "value": 267954768
          }
        },
        "49aed82b08514535bcc8a9654e1956c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21e33784d32242cc89eec3320a131b1d",
            "placeholder": "​",
            "style": "IPY_MODEL_878b578eb24047d591f77701248d638c",
            "value": " 268M/268M [00:01&lt;00:00, 242MB/s]"
          }
        },
        "a5ea3e49c7a444ceb360aa154ea478e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5205e42106fb455ca0adf77086ba101a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be00f6a3713c45f2b43a16896d84dfa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cca5bfaf63304c41a1e74baa94de8cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf50d571ce26482089837db7fd881f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21e33784d32242cc89eec3320a131b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "878b578eb24047d591f77701248d638c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "QNUlqoUKIOZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "metadata": {
        "id": "CcXpGBp_Ty_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f64ffb-7bab-450f-8936-cc2b34379720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_xla[tpu] -f https://storage.googleapis.com/libtpu-releases/index.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT007Oq-Ndms",
        "outputId": "2be7e82f-97da-4506-f366-46483bd89f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/libtpu-releases/index.html\n",
            "Collecting torch_xla[tpu]\n",
            "  Downloading torch_xla-2.5.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torch_xla[tpu]) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_xla[tpu]) (1.26.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from torch_xla[tpu]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_xla[tpu]) (2.32.3)\n",
            "Collecting libtpu-nightly==0.1.dev20240916 (from torch_xla[tpu])\n",
            "  Downloading https://storage.googleapis.com/libtpu-nightly-releases/wheels/libtpu-nightly/libtpu_nightly-0.1.dev20240916%2Bnightly-py3-none-any.whl (123.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.2/123.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tpu-info (from torch_xla[tpu])\n",
            "  Downloading tpu_info-0.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla[tpu]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla[tpu]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla[tpu]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla[tpu]) (2024.12.14)\n",
            "Requirement already satisfied: grpcio>=1.65.5 in /usr/local/lib/python3.10/dist-packages (from tpu-info->torch_xla[tpu]) (1.69.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from tpu-info->torch_xla[tpu]) (4.25.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from tpu-info->torch_xla[tpu]) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->tpu-info->torch_xla[tpu]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->tpu-info->torch_xla[tpu]) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->tpu-info->torch_xla[tpu]) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->tpu-info->torch_xla[tpu]) (0.1.2)\n",
            "Downloading torch_xla-2.5.1-cp310-cp310-manylinux_2_28_x86_64.whl (90.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tpu_info-0.2.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: libtpu-nightly, torch_xla, tpu-info\n",
            "Successfully installed libtpu-nightly-0.1.dev20240916+nightly torch_xla-2.5.1 tpu-info-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "from tokenization_bitnet import BitnetTokenizer\n",
        "tokenizer = BitnetTokenizer.from_pretrained(\"1bitLLM/bitnet_b1_58-xl\")\n",
        "from transformers import AutoConfig\n",
        "config = AutoConfig.from_pretrained(\"1bitLLM/bitnet_b1_58-xl\")\n",
        "\n",
        "\n",
        "model_name = \"1bitLLM/bitnet_b1_58-xl\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "config.save_pretrained(\"./configi\")\n",
        "tokenizer.save_pretrained(\"./bitnet_b1_58-xl\")\n",
        "model.save_pretrained(\"./bitnet_b1_58-xl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "kIriGmHyH3Q8",
        "outputId": "cfeb3688-007a-4606-9ee7-990a0219a78e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_xla/__init__.py:253: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n",
            "WARNING:root:Found CUDA without GPU_NUM_DEVICES. Defaulting to PJRT_DEVICE=CUDA with GPU_NUM_DEVICES=1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tokenization_bitnet'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-00a9aae29f23>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtokenization_bitnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBitnetTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBitnetTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1bitLLM/bitnet_b1_58-xl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1bitLLM/bitnet_b1_58-xl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tokenization_bitnet'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWtjg-lgCLiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb31fea7-4517-4b50-8c38-12f2772c1616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13107\n",
            "13107\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import json\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Certificates/nvdcve-1.1-2024.json\", \"rt\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# print(data[\"CVE_Items\"])  # List of CVEs\n",
        "# print(data[\"CVE_data_type\"])  # Type of data\n",
        "# print(data[\"CVE_data_format\"])  # Format of data\n",
        "# print(data[\"CVE_data_version\"])  # Version of data\n",
        "number = data[\"CVE_data_numberOfCVEs\"] # Number of CVEs of CVEs\n",
        "\n",
        "score = []\n",
        "description = []\n",
        "targets = []\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "for i in range(int(number)):\n",
        "    if(data[\"CVE_Items\"][i][\"impact\"] != {}):\n",
        "        score.append(data[\"CVE_Items\"][i][\"impact\"][\"baseMetricV3\"][\"cvssV3\"][\"baseScore\"])\n",
        "        targets.append(data[\"CVE_Items\"][i][\"impact\"][\"baseMetricV3\"][\"exploitabilityScore\"])\n",
        "        description.append(data[\"CVE_Items\"][i][\"cve\"][\"description\"][\"description_data\"][0][\"value\"])\n",
        "\n",
        "print(len(score))\n",
        "print(len(description))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMJlP5oHhqOh",
        "outputId": "b198f718-3b01-49c0-f0bf-44105744c3b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X_4IswkyXn7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,s,d in zip(score, targets, description):\n",
        "  print(i,s,d)\n",
        "  break"
      ],
      "metadata": {
        "id": "zWiW4Q2Bzg-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc6d9f1-cab0-4216-90f8-35461c4e5e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.8 3.9 A condition exists in FlashArray Purity whereby a local account intended for initial array configuration remains active potentially allowing a malicious actor to gain elevated privileges.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow-cpu\n"
      ],
      "metadata": {
        "id": "AftFPu4SPEcW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5652851-8209-4af1-b985-fc26f01ecace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.17.1\n",
            "Uninstalling tensorflow-2.17.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.17.1.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? y\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 816, in move\n",
            "    os.rename(src, real_dst)\n",
            "OSError: [Errno 18] Invalid cross-device link: '/usr/local/lib/python3.10/dist-packages/tensorflow/' -> '/usr/local/lib/python3.10/dist-packages/~ensorflow'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/uninstall.py\", line 106, in run\n",
            "    uninstall_pathset = req.uninstall(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_install.py\", line 722, in uninstall\n",
            "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_uninstall.py\", line 370, in remove\n",
            "    moved.stash(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_uninstall.py\", line 261, in stash\n",
            "    renames(path, new_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/misc.py\", line 356, in renames\n",
            "    shutil.move(old, new)\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 832, in move\n",
            "    copytree(src, real_dst, copy_function=copy_function,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 559, in copytree\n",
            "    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 495, in _copytree\n",
            "    copytree(srcobj, dstname, symlinks, ignore, copy_function,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 559, in copytree\n",
            "    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 495, in _copytree\n",
            "    copytree(srcobj, dstname, symlinks, ignore, copy_function,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 559, in copytree\n",
            "    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 495, in _copytree\n",
            "    copytree(srcobj, dstname, symlinks, ignore, copy_function,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 559, in copytree\n",
            "    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 495, in _copytree\n",
            "    copytree(srcobj, dstname, symlinks, ignore, copy_function,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 559, in copytree\n",
            "    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 495, in _copytree\n",
            "    copytree(srcobj, dstname, symlinks, ignore, copy_function,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 559, in copytree\n",
            "    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 495, in _copytree\n",
            "    copytree(srcobj, dstname, symlinks, ignore, copy_function,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 559, in copytree\n",
            "    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 495, in _copytree\n",
            "    copytree(srcobj, dstname, symlinks, ignore, copy_function,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 559, in copytree\n",
            "    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 499, in _copytree\n",
            "    copy_function(srcobj, dstname)\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 434, in copy2\n",
            "    copyfile(src, dst, follow_symlinks=follow_symlinks)\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 258, in copyfile\n",
            "    if _HAS_FCOPYFILE:\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting tensorflow-cpu\n",
            "  Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.69.0)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow-cpu)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow-cpu) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow-cpu) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow-cpu) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-cpu) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-cpu) (0.1.2)\n",
            "Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (230.0 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m230.0/230.0 MB\u001b[0m \u001b[31m146.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oTYkg0o1Pl9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip cache purge\n",
        "!pip install --upgrade transformers\n"
      ],
      "metadata": {
        "id": "vbmkS_RGPmEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer , AutoModelForMaskedLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
        "# model = AutoModelForCausalLM.from_pretrained()\n",
        "\n",
        "# Load the model and resize embeddings to match new tokenizer size\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"distilbert/distilbert-base-uncased\", num_labels=1)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "AmUCS5diExhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cfee448-e73e-4a94-f72f-28a66a4c9fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(30522, 768, padding_idx=0)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define a custom Dataset class\n",
        "# class CVEDataset(Dataset):\n",
        "#     def __init__(self, descriptions, scores, exploit_scores, tokenizer, max_length=128):\n",
        "#         self.descriptions = descriptions\n",
        "#         self.scores = scores\n",
        "#         self.exploit_scores = exploit_scores\n",
        "#         self.tokenizer = tokenizer\n",
        "#         self.max_length = max_length\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.descriptions)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         # Tokenize the description\n",
        "#         tokens = self.tokenizer(\n",
        "#             self.descriptions[idx],\n",
        "#             truncation=True,\n",
        "#             padding=\"max_length\",\n",
        "#             max_length=self.max_length,\n",
        "#             return_tensors=\"pt\",\n",
        "#         )\n",
        "\n",
        "#         # CVSS Score as an additional feature\n",
        "#         cvss_score = torch.tensor(self.scores[idx], dtype=torch.float32)\n",
        "\n",
        "#         # Exploitability Score as the target\n",
        "#         target = torch.tensor(self.exploit_scores[idx], dtype=torch.float32)\n",
        "\n",
        "#         # Combine tokenized inputs and CVSS score\n",
        "#         inputs = {\n",
        "#             \"input_ids\": tokens[\"input_ids\"].squeeze(0),\n",
        "#             \"attention_mask\": tokens[\"attention_mask\"].squeeze(0),\n",
        "#             \"cvss_score\": cvss_score,\n",
        "#             \"labels\": target,\n",
        "#         }\n",
        "\n",
        "#         return inputs"
      ],
      "metadata": {
        "id": "byxGEIFdDzPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "class VulnerabilityDataset(Dataset):\n",
        "    def __init__(self, descriptions, scores, targets):\n",
        "        self.descriptions = descriptions\n",
        "        self.scores = scores\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.descriptions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.descriptions[idx]\n",
        "        score = self.scores[idx]\n",
        "        target = self.targets[idx]\n",
        "        return {\"text\": text, \"cvss_score\": score, \"labels\": target}"
      ],
      "metadata": {
        "id": "U2NFGgF5H07u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data\n",
        "train_descriptions = description  # Your CVE descriptions\n",
        "train_scores = score  # CVSS scores\n",
        "train_targets = targets  # Exploitability scores\n",
        "\n",
        "train_dataset = VulnerabilityDataset(train_descriptions, train_scores, train_targets)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# Optimizer and loss\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# Training loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "dCrF3klsE9jv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3a77cf-74ba-425a-e830-3dab7fd10844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForMaskedLM(\n",
              "  (activation): GELUActivation()\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (vocab_transform): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (vocab_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (vocab_projector): Linear(in_features=768, out_features=30522, bias=True)\n",
              "  (mlm_loss_fct): CrossEntropyLoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    model.resize_token_embeddings(len(tokenizer))\n"
      ],
      "metadata": {
        "id": "3I9TKpV8Gng7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t7zwIZz-LPAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tokenizer vocab size:\", tokenizer.vocab_size)\n",
        "sample_text = \"Test CVE description\"\n",
        "encoding = tokenizer(sample_text, return_tensors=\"pt\")\n",
        "print(\"Token IDs:\", encoding['input_ids'])\n",
        "print(\"Max token ID:\", torch.max(encoding['input_ids']))\n"
      ],
      "metadata": {
        "id": "zY6-R19JI5_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm  # Progress bar\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm  # XLA support\n",
        "import torch_xla.distributed.parallel_loader as pl  # Parallel data loader for TPU\n",
        "import torch_xla.utils.utils as xu\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp"
      ],
      "metadata": {
        "id": "D23tZUliWpd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "c5755aaa-1f55-4659-e69d-7972522bd9d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch_xla'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-849f40503b5c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m  \u001b[0;31m# Progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxm\u001b[0m  \u001b[0;31m# XLA support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_loader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m  \u001b[0;31m# Parallel data loader for TPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_xla'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Function to train on TPU\n",
        "def train_model(rank, flags):\n",
        "    # Prepare TPU device\n",
        "    device = xm.xla_device()\n",
        "\n",
        "    # Prepare data\n",
        "    train_descriptions = description  # Your CVE descriptions\n",
        "    train_scores = score  # CVSS scores\n",
        "    train_targets = exploit  # Exploitability scores\n",
        "\n",
        "    # Dataset and DataLoader\n",
        "    train_dataset = VulnerabilityDataset(train_descriptions, train_scores, train_targets)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "    # Optimizer and loss\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    epochs = 3\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        # Wrap DataLoader with ParallelLoader for TPU support\n",
        "        para_loader = pl.MpDeviceLoader(train_loader, device)\n",
        "        for batch in tqdm(para_loader, desc=f\"Epoch {epoch+1}/{epochs} [Training]\"):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            texts = batch['text']\n",
        "            cvss_scores = batch['cvss_score'].clone().detach().unsqueeze(1).to(device)\n",
        "            labels = batch['labels'].clone().detach().unsqueeze(1).to(device)\n",
        "\n",
        "            # Tokenize input text\n",
        "            encoding = tokenizer(\n",
        "                texts,\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=128,\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(**encoding)\n",
        "            output_layer = torch.nn.Linear(outputs, out_features=1)  # Outputs (batch_size, 1)\n",
        "\n",
        "            logits = output_layer.logits.squeeze(-1) + cvss_scores  # Combine CVSS score with model output\n",
        "\n",
        "            loss = loss_fn(logits, labels)\n",
        "            loss.backward()\n",
        "            xm.optimizer_step(optimizer)  # XLA-specific step for optimization\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Log TPU metrics for debugging\n",
        "        xm.master_print(met.metrics_report())\n",
        "\n",
        "    # Save the model\n",
        "    xm.save(model.state_dict(), \"bitnet_exploit_model.pth\")\n",
        "    tokenizer.save_pretrained(\"bitnet_exploit_model\")\n",
        "\n",
        "\n",
        "# Start training on TPU using xmp.spawn\n",
        "if __name__ == '__main__':\n",
        "    flags = {}\n",
        "    xmp.spawn(train_model, args=(flags,), nprocs=8, start_method='fork')\n"
      ],
      "metadata": {
        "id": "k8RMijEHNs2Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "48a03f63-76ee-4f70-acaf-2720dba0913c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'xmp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2d127463bdd8>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'xmp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-57_jqyoWh7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        texts = batch['text']\n",
        "        cvss_scores = batch['cvss_score'].clone().detach().unsqueeze(1).to(device)\n",
        "        labels = batch['labels'].clone().detach().unsqueeze(1).to(device)\n",
        "\n",
        "\n",
        "        # Tokenize input text\n",
        "        encoding = tokenizer(\n",
        "            texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        print(len(encoding['input_ids']))\n",
        "\n",
        "        outputs = model(**encoding)\n",
        "        logits = outputs.logits.squeeze(-1) + cvss_scores  # Combine CVSS score with model output\n",
        "\n",
        "        loss = loss_fn(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"bitnet_exploit_model\")\n",
        "tokenizer.save_pretrained(\"bitnet_exploit_model\")"
      ],
      "metadata": {
        "id": "98VESxZbFAEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm  # Import tqdm\n",
        "import time  # For time estimation if needed\n",
        "\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    # Add tqdm progress bar for training\n",
        "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Training]\", leave=False)\n",
        "    for batch in train_bar:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Data processing\n",
        "        texts = batch['text']\n",
        "        cvss_scores = batch['cvss_score'].clone().detach().unsqueeze(1).to(device)\n",
        "        labels = batch['labels'].clone().detach().unsqueeze(1).to(device)\n",
        "        encoding = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # print(encoding)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**encoding)\n",
        "        logits = outputs.logits.squeeze(-1) + cvss_scores\n",
        "        loss = loss_fn(logits, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Update tqdm with current loss\n",
        "        train_bar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    # Validation Loop with Progress Bar\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Validation]\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for batch in val_bar:\n",
        "            texts = batch['text']\n",
        "            cvss_scores = batch['cvss_score'].clone().detach().unsqueeze(1).to(device)\n",
        "            labels = batch['labels'].clone().detach().unsqueeze(1).to(device)\n",
        "            encoding = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
        "\n",
        "            # print(encoding.shape())\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(**encoding)\n",
        "            logits = outputs.logits.squeeze(-1) + cvss_scores\n",
        "            loss = loss_fn(logits, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Update tqdm with current loss\n",
        "            val_bar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"bitnet_exploit_model\")\n",
        "tokenizer.save_pretrained(\"bitnet_exploit_model\")\n"
      ],
      "metadata": {
        "id": "sjXnE8-4Kl_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "scaler = MinMaxScaler()\n",
        "# score = scaler.fit_transform(score)  # Scale numerical features\n",
        "# score = scaler.fit_transform(score)  # Scale numerical features\n",
        "targets = scaler.fit_transform(np.array(targets).reshape(-1, 1)).squeeze()  # Scale targets\n",
        "score = scaler.fit_transform(np.array(score).reshape(-1, 1)).squeeze()  # Scale targets"
      ],
      "metadata": {
        "id": "kYJ0jqY0jA7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "hell = zip(score, targets, description)\n",
        "print(len(hell))\n",
        "for i,t,s in random.sample(hell, 20):\n",
        "  print(i,t,s)\n",
        "  break"
      ],
      "metadata": {
        "id": "GAzTUMS7PrFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ELlE3YO3jBUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Dummy dataset class\n",
        "class NVDDataset(Dataset):\n",
        "    def __init__(self, descriptions, cvss_scores, targets, tokenizer, max_length):\n",
        "        self.descriptions = descriptions\n",
        "        self.cvss_scores = cvss_scores\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.descriptions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize text description\n",
        "        encoding = self.tokenizer(\n",
        "            self.descriptions[idx],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'cvss_scores': torch.tensor(self.cvss_scores[idx], dtype=torch.float32),\n",
        "            'target': torch.tensor(self.targets[idx], dtype=torch.float32)\n",
        "        }\n",
        "\n",
        "# Simple Model Class\n",
        "class NVDRegressionModel(nn.Module):\n",
        "    def __init__(self, pretrained_model_name, config,num_numerical_features):\n",
        "        super(NVDRegressionModel, self).__init__()\n",
        "        # model = LlamaForCausalLM.from_pretrained(\"meta-llama/Bitnet-2-7b-hf\")\n",
        "        # self.transformer = LlamaForCausalLM.from_pretrained(pretrained_model_name, config=config)\n",
        "        self.transformer = AutoModelForCausalLM.from_pretrained(pretrained_model_name, config=config)\n",
        "        self.linear = nn.Linear(self.transformer.config.hidden_size + num_numerical_features, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, cvss_scores):\n",
        "        # print(\"Input IDs shape:\", input_ids.shape)\n",
        "        # print(\"Attention mask shape:\", attention_mask.shape)\n",
        "        # print(\"Numerical features shape:\", cvss_scores.shape)\n",
        "        transformer_outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask, output_attentions=True)\n",
        "        cls_embedding = transformer_outputs.last_hidden_state\n",
        "        # CLS token representation\n",
        "        # print(\"CLS Embedding shape:\", cls_embedding.shape)\n",
        "        # print(\"CLS Embedding min/max:\", cls_embedding.min().item(), cls_embedding.max().item())\n",
        "        # print(\"CLS Embedding (first 5 rows):\", cls_embedding[:5])\n",
        "        # transformer_outputs = model.transformer(input_ids=input_ids, attention_mask=attention_mask, output_attentions=True)\n",
        "        attention_scores = transformer_outputs.attentions  # List of attention tensors\n",
        "        # for i, scores in enumerate(attention_scores):\n",
        "          # print(f\"Layer {i} Attention min/max: {scores.min()}, {scores.max()}\")\n",
        "\n",
        "        combined_features = torch.cat((cls_embedding, cvss_scores.unsqueeze(1)), dim=1)\n",
        "        # combined_features = torch.cat((cls_embedding, cvss_scores), dim=1)  # Combine embeddings and numerical features\n",
        "        output = self.linear(combined_features)\n",
        "        return output.squeeze()\n",
        "\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "scaler = GradScaler()\n",
        "from torch.utils.checkpoint import checkpoint\n",
        "\n",
        "# Enable gradient checkpointing\n",
        "\n",
        "\n",
        "\n",
        "# Training Function\n",
        "def train(model, dataloader, optimizer, loss_fn, device):\n",
        "    model.transformer.gradient_checkpointing_enable()\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(dataloader, desc=\"Processing\", total=len(dataloader)):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        # print(\"Max Token ID:\", input_ids.max().item())\n",
        "        # print(\"Min Token ID:\", input_ids.min().item())\n",
        "\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        cvss_scores = batch['cvss_scores'].to(device)\n",
        "        targets = batch['target'].to(device)\n",
        "        # print(input_ids.shape)\n",
        "        # print(attention_mask.shape)\n",
        "        # print(cvss_scores.shape)\n",
        "        # print(targets.shape)\n",
        "\n",
        "\n",
        "        print(\"CVSS Scores:\", cvss_scores[:5])\n",
        "        print(\"Targets:\", targets[:5])\n",
        "\n",
        "        cvss_scores = torch.nan_to_num(cvss_scores, nan=0.0, posinf=1.0, neginf=0.0)\n",
        "        targets = torch.nan_to_num(targets, nan=0.0, posinf=1.0, neginf=0.0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        # predictions = model(input_ids, attention_mask, cvss_scores)\n",
        "        # loss = loss_fn(predictions, targets)\n",
        "    #     loss.backward()\n",
        "    #     optimizer.step()\n",
        "\n",
        "    #     total_loss += loss.item()\n",
        "    # return total_loss / len(dataloader)\n",
        "\n",
        "    # Use autocast for mixed precision\n",
        "        with autocast():\n",
        "            predictions = model(input_ids, attention_mask, cvss_scores)\n",
        "            loss = loss_fn(predictions, targets)\n",
        "            print(loss)\n",
        "\n",
        "        # Scale the loss and perform backward pass\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    predictions, actuals = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            cvss_scores = batch['cvss_scores'].to(device)\n",
        "            targets = batch['target'].to(device)\n",
        "\n",
        "            preds = model(input_ids, attention_mask, cvss_scores)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            actuals.extend(targets.cpu().numpy())\n",
        "    return predictions, actuals"
      ],
      "metadata": {
        "id": "MtlKiNn9jBtH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4432748a-bf5f-4f96-e148-703f50dd11bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-114a606cd0ee>:66: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.reset_peak_memory_stats()\n"
      ],
      "metadata": {
        "id": "tEHWD36In9s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export CUDA_LAUNCH_BLOCKING=1\n"
      ],
      "metadata": {
        "id": "eWuyvIiYXyAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze most layers of the model\n",
        "def freeze_model_layers(model, num_layers_to_freeze=None):\n",
        "    \"\"\"\n",
        "    Freeze the layers of the model.\n",
        "    If num_layers_to_freeze is None, all layers are frozen except the last few.\n",
        "    \"\"\"\n",
        "    # If num_layers_to_freeze is not provided, freeze all layers except the final ones\n",
        "    if num_layers_to_freeze is None:\n",
        "        num_layers_to_freeze = len(model.transformer.h) - 2  # Keep the last two layers trainable\n",
        "\n",
        "    # Freeze the embeddings\n",
        "    for param in model.transformer.wte.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.transformer.wpe.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Freeze the first `num_layers_to_freeze` transformer blocks\n",
        "    for layer in model.transformer.h[:num_layers_to_freeze]:\n",
        "        for param in layer.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # Print the layers that are frozen\n",
        "    print(f\"Froze {num_layers_to_freeze} layers of the transformer.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f_S2blNLcsTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze most layers of the model\n",
        "def freeze_model_layers(model, num_layers_to_freeze=None):\n",
        "    \"\"\"\n",
        "    Freeze the layers of the model.\n",
        "    If num_layers_to_freeze is None, freeze all layers except the last few.\n",
        "    \"\"\"\n",
        "    # Inspect the model's architecture\n",
        "    for name, module in model.named_children():\n",
        "        print(f\"Layer: {name}, Type: {type(module)}\")\n",
        "\n",
        "    # Find transformer blocks dynamically\n",
        "    transformer_blocks = None\n",
        "    for name, module in model.named_children():\n",
        "        if \"transformer\" in name.lower():\n",
        "            transformer_blocks = module\n",
        "            break\n",
        "\n",
        "    if transformer_blocks is None:\n",
        "        raise ValueError(\"Cannot find transformer blocks in the model.\")\n",
        "\n",
        "    # Dynamically access the layers within the transformer\n",
        "    transformer_layers = list(transformer_blocks.children())\n",
        "    total_layers = len(transformer_layers)\n",
        "    print(total_layers)\n",
        "    if num_layers_to_freeze is None:\n",
        "        num_layers_to_freeze = total_layers - 2  # Default: Freeze all but the last 2 layers\n",
        "\n",
        "    # Freeze specified number of layers\n",
        "    for i, layer in enumerate(transformer_layers[:num_layers_to_freeze]):\n",
        "        for param in layer.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    print(f\"Froze {num_layers_to_freeze} out of {total_layers} transformer layers.\")\n"
      ],
      "metadata": {
        "id": "lDjeaMRAPa9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer , AutoModelForSequenceClassification\n",
        "# from tokenization_bitnet import BitnetTokenizer\n",
        "from tqdm import tqdm\n",
        "# Main pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    # Hyperparameters\n",
        "    # PRETRAINED_MODEL_NAME = \"distilbert-base-uncased\"\n",
        "    PRETRAINED_MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
        "    MAX_LENGTH = 64\n",
        "    BATCH_SIZE = 32\n",
        "    EPOCHS = 3\n",
        "    LR = 1e-5\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    # DEVICE = \"cpu\"\n",
        "\n",
        "    # Sample data (replace with your actual dataset)\n",
        "    # descriptions = [\"Sample CVE description 1\", \"Sample CVE description 2\"] * 100\n",
        "    # cvss_scores = [[5.4], [7.8]] * 100  # Numerical features\n",
        "    # targets = [0.5, 0.8] * 100  # Exploitability score\n",
        "\n",
        "    from transformers import AutoConfig\n",
        "    config = AutoConfig.from_pretrained(PRETRAINED_MODEL_NAME)\n",
        "    config.use_cache = False  # Disable caching\n",
        "\n",
        "    descriptions = description\n",
        "    cvss_scores = score\n",
        "    targets = targets\n",
        "\n",
        "    # Tokenizer and Dataset\n",
        "    tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
        "    # Set an existing token as the pad token\n",
        "    if tokenizer.pad_token is None:\n",
        "      tokenizer.pad_token = tokenizer.eos_token  # Use the end-of-sequence token as padding\n",
        "\n",
        "    train_desc, val_desc, train_cvss, val_cvss, train_targets, val_targets = train_test_split(\n",
        "        descriptions, cvss_scores, targets, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    print(\"Tokenizer vocab size:\", tokenizer.vocab_size)\n",
        "\n",
        "\n",
        "    train_dataset = NVDDataset(train_desc, train_cvss, train_targets, tokenizer, MAX_LENGTH)\n",
        "    val_dataset = NVDDataset(val_desc, val_cvss, val_targets, tokenizer, MAX_LENGTH)\n",
        "\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=2)\n",
        "\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Model, Optimizer, and Loss\n",
        "    model = NVDRegressionModel(PRETRAINED_MODEL_NAME, config=config, num_numerical_features=1).to(DEVICE)\n",
        "    # Resize the token embeddings to match the new vocabulary size\n",
        "    if '[PAD]' in tokenizer.all_special_tokens:\n",
        "      model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    print(\"Model vocab size:\", model.transformer.config.vocab_size)\n",
        "    # print(\"Max token ID in input_ids:\", .max())\n",
        "    # print(\"Model vocab size:\", model.transformer.config.vocab_size)\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    for batch in train_loader:\n",
        "      count = count + 1\n",
        "      input_ids = batch['input_ids']\n",
        "      if input_ids.max() >= model.transformer.config.vocab_size:\n",
        "        print(input_ids.max())\n",
        "        raise ValueError(\"Token ID out of range! Check tokenizer and model vocab alignment.\")\n",
        "\n",
        "    # freeze_model_layers(model, num_layers_to_freeze=len(model.transformer.h) - 2)\n",
        "    freeze_model_layers(model)\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "      print(f\"{name}: {'Trainable' if param.requires_grad else 'Frozen'}\")\n",
        "\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_loss = train(model, train_loader, optimizer, loss_fn, DEVICE)\n",
        "        print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Evaluation\n",
        "    predictions, actuals = evaluate(model, val_loader, DEVICE)\n",
        "    print(\"Sample Predictions:\", predictions[:5])\n",
        "    print(\"Sample Actuals:\", actuals[:5])"
      ],
      "metadata": {
        "id": "BqTES7xzjEkA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0f6fdf1-538c-4929-a1c5-b0ef05dfaa33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer vocab size: 32000\n",
            "Model vocab size: 32000\n",
            "Layer: transformer, Type: <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'>\n",
            "Layer: linear, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "2\n",
            "Froze 0 out of 2 transformer layers.\n",
            "transformer.model.embed_tokens.weight: Trainable\n",
            "transformer.model.layers.0.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.0.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.0.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.0.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.0.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.0.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.0.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.0.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.0.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.1.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.1.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.1.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.1.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.1.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.1.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.1.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.1.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.1.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.2.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.2.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.2.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.2.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.2.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.2.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.2.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.2.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.2.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.3.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.3.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.3.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.3.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.3.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.3.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.3.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.3.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.3.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.4.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.4.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.4.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.4.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.4.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.4.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.4.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.4.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.4.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.5.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.5.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.5.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.5.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.5.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.5.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.5.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.5.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.5.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.6.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.6.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.6.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.6.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.6.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.6.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.6.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.6.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.6.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.7.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.7.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.7.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.7.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.7.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.7.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.7.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.7.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.7.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.8.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.8.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.8.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.8.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.8.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.8.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.8.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.8.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.8.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.9.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.9.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.9.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.9.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.9.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.9.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.9.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.9.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.9.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.10.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.10.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.10.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.10.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.10.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.10.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.10.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.10.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.10.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.11.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.11.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.11.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.11.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.11.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.11.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.11.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.11.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.11.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.12.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.12.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.12.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.12.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.12.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.12.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.12.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.12.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.12.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.13.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.13.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.13.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.13.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.13.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.13.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.13.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.13.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.13.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.14.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.14.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.14.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.14.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.14.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.14.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.14.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.14.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.14.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.15.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.15.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.15.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.15.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.15.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.15.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.15.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.15.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.15.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.16.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.16.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.16.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.16.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.16.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.16.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.16.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.16.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.16.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.17.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.17.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.17.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.17.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.17.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.17.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.17.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.17.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.17.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.18.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.18.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.18.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.18.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.18.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.18.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.18.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.18.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.18.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.19.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.19.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.19.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.19.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.19.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.19.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.19.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.19.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.19.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.20.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.20.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.20.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.20.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.20.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.20.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.20.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.20.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.20.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.layers.21.self_attn.q_proj.weight: Trainable\n",
            "transformer.model.layers.21.self_attn.k_proj.weight: Trainable\n",
            "transformer.model.layers.21.self_attn.v_proj.weight: Trainable\n",
            "transformer.model.layers.21.self_attn.o_proj.weight: Trainable\n",
            "transformer.model.layers.21.mlp.gate_proj.weight: Trainable\n",
            "transformer.model.layers.21.mlp.up_proj.weight: Trainable\n",
            "transformer.model.layers.21.mlp.down_proj.weight: Trainable\n",
            "transformer.model.layers.21.input_layernorm.weight: Trainable\n",
            "transformer.model.layers.21.post_attention_layernorm.weight: Trainable\n",
            "transformer.model.norm.weight: Trainable\n",
            "transformer.lm_head.weight: Trainable\n",
            "linear.weight: Trainable\n",
            "linear.bias: Trainable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   0%|          | 0/328 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CVSS Scores: tensor([7.8000, 7.8000, 8.8000, 9.8000, 4.7000], device='cuda:0')\n",
            "Targets: tensor([1.8000, 1.8000, 2.8000, 3.9000, 1.0000], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-0c03b16f9587>:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
            "Processing:   0%|          | 0/328 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Model didnt return hidden state",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-05301bd17c02>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# Training Loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-0c03b16f9587>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# Use autocast for mixed precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvss_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-0c03b16f9587>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, cvss_scores)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mcls_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model didnt return hidden state\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;31m# CLS token representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# print(\"CLS Embedding shape:\", cls_embedding.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Model didnt return hidden state"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\n",
        "import numpy as np\n",
        "\n",
        "def compute_regression_metrics(predictions, actuals):\n",
        "    # Mean Absolute Error\n",
        "    mae = mean_absolute_error(actuals, predictions)\n",
        "\n",
        "    # Mean Squared Error\n",
        "    mse = mean_squared_error(actuals, predictions)\n",
        "\n",
        "    # Root Mean Squared Error\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    # R-squared\n",
        "    r2 = r2_score(actuals, predictions)\n",
        "\n",
        "    # Explained Variance Score\n",
        "    evs = explained_variance_score(actuals, predictions)\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "    print(f\"R-squared (R²): {r2:.4f}\")\n",
        "    print(f\"Explained Variance Score: {evs:.4f}\")\n",
        "\n",
        "    return {\"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R²\": r2, \"Explained Variance Score\": evs}\n",
        "\n",
        "# Example usage\n",
        "predictions, actuals = evaluate(model, val_loader, DEVICE)\n",
        "print(\"Sample Predictions:\", predictions[:5])\n",
        "print(\"Sample Actuals:\", actuals[:5])\n",
        "\n",
        "# Compute regression metrics\n",
        "metrics = compute_regression_metrics(predictions, actuals)\n"
      ],
      "metadata": {
        "id": "FTwH9DXFmSWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e155ece-4401-4cfc-80c7-8beae29eb346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Predictions: [1.8329941, 2.751694, 2.1770105, 2.1772223, 1.8384278]\n",
            "Sample Actuals: [2.8, 2.8, 3.9, 3.9, 2.3]\n",
            "Mean Absolute Error (MAE): 0.7844\n",
            "Mean Squared Error (MSE): 0.9162\n",
            "Root Mean Squared Error (RMSE): 0.9572\n",
            "R-squared (R²): -0.1733\n",
            "Explained Variance Score: -0.0854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max(actuals))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npKlfxS2qN0H",
        "outputId": "220ae2c1-d75e-4b88-b6ed-7a9cc0a86440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530,
          "referenced_widgets": [
            "8a527b72ba564c079765ff50fb2eb757",
            "2ce05a51d8084243ae2ad7ce1116df69",
            "49085b35aa054e048af6f2b036c459b5",
            "49aed82b08514535bcc8a9654e1956c5",
            "a5ea3e49c7a444ceb360aa154ea478e8",
            "5205e42106fb455ca0adf77086ba101a",
            "be00f6a3713c45f2b43a16896d84dfa0",
            "cca5bfaf63304c41a1e74baa94de8cf8",
            "cf50d571ce26482089837db7fd881f35",
            "21e33784d32242cc89eec3320a131b1d",
            "878b578eb24047d591f77701248d638c"
          ]
        },
        "id": "deKAeTR5sfdh",
        "outputId": "00c75e41-2cc7-49a6-fbfd-b2113ee978eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a527b72ba564c079765ff50fb2eb757"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-bb0a3fdbd102>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-bb0a3fdbd102>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         encoding = self.tokenizer(\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2858\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2859\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2860\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2968\u001b[0m             )\n\u001b[1;32m   2969\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2970\u001b[0;31m             return self.encode_plus(\n\u001b[0m\u001b[1;32m   2971\u001b[0m                 \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2972\u001b[0m                 \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3036\u001b[0m         \u001b[0;31m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3037\u001b[0;31m         padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(\n\u001b[0m\u001b[1;32m   3038\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m             \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtruncation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_get_padding_truncation_strategies\u001b[0;34m(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2760\u001b[0m         \u001b[0;31m# Test if we have a padding token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpadding_strategy\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mPaddingStrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDO_NOT_PAD\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2762\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2763\u001b[0m                 \u001b[0;34m\"Asking to pad but the tokenizer does not have a padding token. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2764\u001b[0m                 \u001b[0;34m\"Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HoEdBloUs-Ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_labels(exploitability_scores):\n",
        "    # Define thresholds for conversion (for example)\n",
        "    labels = []\n",
        "    for score in exploitability_scores:\n",
        "        if score < 1.5:\n",
        "            labels.append(0)  # Low exploitability\n",
        "        elif score < 3.2:\n",
        "            labels.append(1)  # Medium exploitability\n",
        "        else:\n",
        "            labels.append(2)  # High exploitability\n",
        "    return np.array(labels)\n",
        "\n",
        "# Example: convert continuous scores to labels\n",
        "predictions_labels = convert_to_labels(predictions)\n",
        "actuals_labels = convert_to_labels(actuals)\n"
      ],
      "metadata": {
        "id": "bWYD24FPs-kO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(actuals_labels, predictions_labels)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(actuals_labels, predictions_labels, average=None)\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(actuals_labels, predictions_labels)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "SIbSx2whtAq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "642f12ff-15a4-4698-c64e-13eefc46a05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6915\n",
            "Precision: [0.         0.69436997 0.        ]\n",
            "Recall: [0.         0.99615385 0.        ]\n",
            "F1 Score: [0.         0.81832543 0.        ]\n",
            "Confusion Matrix:\n",
            "[[   0  175    0]\n",
            " [   7 1813    0]\n",
            " [   4  623    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LwUG2pYxqZMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Dummy dataset class\n",
        "class NVDDataset(Dataset):\n",
        "    def __init__(self, descriptions, cvss_scores, targets, tokenizer, max_length):\n",
        "        self.descriptions = descriptions\n",
        "        self.cvss_scores = cvss_scores\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.descriptions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.descriptions[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"cvss_scores\": torch.tensor(self.cvss_scores[idx], dtype=torch.float32),\n",
        "            \"target\": torch.tensor(self.targets[idx], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "\n",
        "# Model class for regression\n",
        "class NVDRegressionModel(nn.Module):\n",
        "    def __init__(self, pretrained_model_name, num_numerical_features):\n",
        "        super(NVDRegressionModel, self).__init__()\n",
        "        self.transformer = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=1)\n",
        "        self.linear = nn.Linear(self.transformer.config.hidden_size + num_numerical_features, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, cvss_scores):\n",
        "        outputs = self.transformer.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # First token for regression\n",
        "        combined_features = torch.cat((cls_embedding, cvss_scores.unsqueeze(1)), dim=1)\n",
        "        output = self.linear(combined_features)\n",
        "        return output.squeeze()\n",
        "\n",
        "\n",
        "# Main pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    # Hyperparameters\n",
        "    PRETRAINED_MODEL_NAME = \"distilbert/distilbert-base-uncased\"\n",
        "    MAX_LENGTH = 64\n",
        "    BATCH_SIZE = 32\n",
        "    EPOCHS = 3\n",
        "    LR = 1e-5\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "\n",
        "    # Tokenizer and Dataset\n",
        "    tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    train_desc, val_desc, train_cvss, val_cvss, train_targets, val_targets = train_test_split(\n",
        "        descriptions, cvss_scores, targets, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    train_dataset = NVDDataset(train_desc, train_cvss, train_targets, tokenizer, MAX_LENGTH)\n",
        "    val_dataset = NVDDataset(val_desc, val_cvss, val_targets, tokenizer, MAX_LENGTH)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Model, Optimizer, and Loss\n",
        "    model = NVDRegressionModel(PRETRAINED_MODEL_NAME, num_numerical_features=1).to(DEVICE)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "            cvss_scores = batch[\"cvss_scores\"].to(DEVICE)\n",
        "            targets = batch[\"target\"].to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(input_ids, attention_mask, cvss_scores)\n",
        "            loss = loss_fn(predictions, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Train Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    predictions, actuals = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "            cvss_scores = batch[\"cvss_scores\"].to(DEVICE)\n",
        "            targets = batch[\"target\"].to(DEVICE)\n",
        "\n",
        "            preds = model(input_ids, attention_mask, cvss_scores)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            actuals.extend(targets.cpu().numpy())\n",
        "\n",
        "    print(\"Sample Predictions:\", predictions[:5])\n",
        "    print(\"Sample Actuals:\", actuals[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "CuTAJI2KqZft",
        "outputId": "6e259431-256f-429c-c0ce-3124e42321de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'descriptions' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-bacd35ca62bb>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     train_desc, val_desc, train_cvss, val_cvss, train_targets, val_targets = train_test_split(\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mdescriptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvss_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     )\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'descriptions' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the finetuned model and tokenizer\n",
        "# Save the model's state dictionary\n",
        "torch.save(model.state_dict(), 'nvd_regression_model.pth')\n",
        "\n",
        "# Compress the saved model folder into a zip file for easy downloading\n",
        "import shutil\n",
        "shutil.make_archive('nvd_regression_model.pth', 'zip', './nvd_regression_model.pth')\n"
      ],
      "metadata": {
        "id": "RzfnNd32uHwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BitnetForSequenceClassification, BitnetTokenizer, Trainer, TrainingArguments\n",
        "\n",
        "# Load BitNet tokenizer and model (make sure it's available in the Hugging Face hub)\n",
        "tokenizer = BitnetTokenizer.from_pretrained('facebook/bitnet-base')\n",
        "model = BitnetForSequenceClassification.from_pretrained('facebook/bitnet-base', num_labels=3)  # Assuming 3 classes for exploitability scores\n"
      ],
      "metadata": {
        "id": "h7Gn4JjVvYv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: gpu not free yet. colab saying 14.7 gb in use # prompt: clear the the gpu space, its filled to 14.7 gb due to a failed process. i wanna clear it back\n",
        "# import torch\n",
        "# # Method 1: Using torch.cuda.empty_cache()\n",
        "# torch.cuda.empty_cache()\n",
        "# # Method 2: Resetting peak memory stats (optional, but good practice)\n",
        "# torch.cuda.reset_peak_memory_stats()\n",
        "# # Optionally, check GPU memory usage again\n",
        "# print(torch.cuda.memory_summary(device=None, abbreviated=False)) these didn't help\n",
        "\n",
        "import gc\n",
        "\n",
        "# Method 1: Delete unneeded variables\n",
        "# del model, tokenizer, train_loader, val_loader, optimizer, loss_fn # etc. - delete any large variables you're no longer using\n",
        "\n",
        "# Method 2: Force garbage collection\n",
        "gc.collect()\n",
        "\n",
        "# Method 3: Empty PyTorch CUDA cache (if applicable)\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Method 4: Reset peak memory statistics (optional, for monitoring)\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "# Optionally, check GPU memory usage again\n",
        "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
      ],
      "metadata": {
        "id": "-horrEjjY0_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Dummy dataset class\n",
        "class NVDDataset(Dataset):\n",
        "    def __init__(self, descriptions, cvss_scores, targets, tokenizer, max_length):\n",
        "        self.descriptions = descriptions\n",
        "        self.cvss_scores = cvss_scores\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.descriptions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.descriptions[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"cvss_scores\": torch.tensor(self.cvss_scores[idx], dtype=torch.float32),\n",
        "            \"target\": torch.tensor(self.targets[idx], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "\n",
        "# Model class for regression\n",
        "class NVDRegressionModel(nn.Module):\n",
        "    def __init__(self, pretrained_model_name, num_numerical_features):\n",
        "        super(NVDRegressionModel, self).__init__()\n",
        "        self.transformer = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=1)\n",
        "        self.linear = nn.Linear(self.transformer.config.hidden_size + num_numerical_features, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, cvss_scores):\n",
        "        outputs = self.transformer.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # First token for regression\n",
        "        combined_features = torch.cat((cls_embedding, cvss_scores.unsqueeze(1)), dim=1)\n",
        "        output = self.linear(combined_features)\n",
        "        return output.squeeze()"
      ],
      "metadata": {
        "id": "wZBZEXKec4zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yZsbomTgc7GI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}